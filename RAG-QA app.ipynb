{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37391c57-a96e-4510-b168-64cb236cccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai==1.54.5\n",
    "!pip install langchain-core==0.3.19\n",
    "!pip install azure-ai-openai\n",
    "!pip install langchain==0.3.7\n",
    "!pip install langchain-community==0.3.7\n",
    "!pip install langchain-openai==0.2.9\n",
    "!pip install pypdf\n",
    "!pip install python-docx\n",
    "!pip install networkx\n",
    "!pip install openpyxl\n",
    "!pip install \"unstructured[excel]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0dd6eb-7d76-45e1-97d8-c0d1d56a4705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed ./DataSource1-D365_BatchProcess.docx. Total splits: 75\n",
      "Successfully processed ./LangChain.pdf. Total splits: 19\n",
      "Successfully processed ./Ind-Japan- 2010 Population Comparison.xlsx. Total splits: 4\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "def load_document(file_path):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    \n",
    "    if file_extension.lower() == \".pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_extension.lower() in [\".xlsx\", \".xls\"]:\n",
    "        loader = UnstructuredExcelLoader(file_path, mode=\"elements\")\n",
    "    elif file_extension.lower() in [\".docx\", \".doc\"]:\n",
    "        loader = UnstructuredWordDocumentLoader(file_path, mode=\"elements\", strategy=\"fast\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "    \n",
    "    return loader.load()\n",
    "\n",
    "def split_documents(docs, chunk_size=1000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    \"./DataSource1-D365_BatchProcess.docx\",\n",
    "    \"./LangChain.pdf\",\n",
    "    \"./Ind-Japan- 2010 Population Comparison.xlsx\"\n",
    "]\n",
    "\n",
    "# Process and split documents\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        docs = load_document(file_path)\n",
    "        splits = split_documents(docs)\n",
    "        print(f\"Successfully processed {file_path}. Total splits: {len(splits)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44524e04-b925-458d-8330-058ffa314ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Azure OpenAI configuration\n",
    "azure_openai_endpoint = \" \"  # Provide your endpoint\n",
    "azure_openai_api_version = \" \" # Provide the api-version\n",
    "azure_openai_key = \" \" # Provide the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396d4a9-8eb2-4af2-823c-021e4fbebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS  \n",
    "import openai\n",
    "\n",
    "# Initialize embeddings\n",
    "azure_embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\" \",  # Provide the model name\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    openai_api_key = azure_openai_key,\n",
    "    openai_api_version=azure_openai_api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d32ffc3-860d-41a3-b259-337810719d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  \n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=azure_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665533b-e51e-4035-9446-adc211c412eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_Type = \"azure\"\n",
    "azure_openai_Endpoint = \" \" # Your endpoint\n",
    "azure_openai_Key = \" \" # Your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3c24e-bd1f-4f4b-ab5e-346d39f5200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Initialize Azure OpenAI LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key= azure_openai_Key,\n",
    "    azure_endpoint= azure_openai_Endpoint,\n",
    "    deployment_name= \"\",  # Your model name\n",
    "    api_version = \"\",  # Your api-version\n",
    "    openai_api_type = \"\" # Your api-type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3195ead-83a0-4b08-8d10-161b47e9f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06de61f4-23e1-4e81-82c2-1aa08398c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8adf32c4-0edd-443d-b9f7-50a8f1204d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "#Creating Prompt Template\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt_sample = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab6d2fa8-fc43-434f-ad4b-04efb02ef588",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | prompt_sample\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d414658-5c4b-4f6e-9763-1f28ce31db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaders in LangChain are essential for ingesting and processing data from various sources, such as files, databases, or web pages. They help convert raw documents into a structured format that can be indexed, making it easier to retrieve and query information later. By standardizing the data input, document loaders enhance the efficiency and accuracy of the indexing process within LangChain.\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt_sample)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"How do document loaders contribute to building indexes in LangChain?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9026bd-d974-4e28-b4ae-6458d8854a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
